{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440b9994",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>step 0\n",
      "   weights 0   0   0\n",
      "             score=0.4375\n",
      ">>step 1\n",
      "   weights -1.0   -3.0   -0.2\n",
      "             score=0.5625\n",
      ">>step 2\n",
      "   weights 0.0   3.0   0.0\n",
      "             score=0.4375\n",
      ">>step 3\n",
      "   weights -1.0   0.0   -0.2\n",
      "             score=0.5625\n",
      ">>step 4\n",
      "   weights 0.0   6.0   0.0\n",
      "             score=0.4375\n",
      ">>step 5\n",
      "   weights -1.0   3.0   -0.2\n",
      "             score=0.5\n",
      ">>step 6\n",
      "   weights -2.0   0.0   -0.4\n",
      "             score=0.5625\n",
      ">>step 7\n",
      "   weights -1.0   6.0   -0.2\n",
      "             score=0.5\n",
      ">>step 8\n",
      "   weights -2.0   3.0   -0.4\n",
      "             score=0.5\n",
      ">>step 9\n",
      "   weights -3.0   0.0   -0.6000000000000001\n",
      "             score=0.5625\n",
      ">>step 10\n",
      "   weights -2.0   6.0   -0.4000000000000001\n",
      "             score=0.5\n",
      ">>step 11\n",
      "   weights -3.0   3.0   -0.6000000000000001\n",
      "             score=0.6875\n",
      ">>step 12\n",
      "   weights -4.0   0.0   -0.8\n",
      "             score=0.5625\n",
      ">>step 13\n",
      "   weights -3.0   6.0   -0.6000000000000001\n",
      "             score=0.5\n",
      ">>step 14\n",
      "   weights -4.0   3.0   -0.8\n",
      "             score=0.6875\n",
      ">>step 15\n",
      "   weights -5.0   0.0   -1.0\n",
      "             score=0.5625\n",
      ">>step 16\n",
      "   weights -4.0   6.0   -0.8\n",
      "             score=0.5\n",
      ">>step 17\n",
      "   weights -5.0   3.0   -1.0\n",
      "             score=0.5625\n",
      ">>step 18\n",
      "   weights -6.0   0.0   -1.2\n",
      "             score=0.5625\n",
      ">>step 19\n",
      "   weights -5.0   6.0   -1.0\n",
      "             score=0.625\n",
      ">>step 20\n",
      "   weights -6.0   3.0   -1.2\n",
      "             score=0.625\n",
      ">>step 21\n",
      "   weights -7.0   0.0   -1.4\n",
      "             score=0.5625\n",
      ">>step 22\n",
      "   weights -6.0   6.0   -1.2\n",
      "             score=0.6875\n",
      ">>step 23\n",
      "   weights -7.0   3.0   -1.4\n",
      "             score=0.6875\n",
      ">>step 24\n",
      "   weights -8.0   0.0   -1.5999999999999999\n",
      "             score=0.5625\n",
      ">>step 25\n",
      "   weights -7.0   6.0   -1.4\n",
      "             score=0.6875\n",
      ">>step 26\n",
      "   weights -8.0   3.0   -1.5999999999999999\n",
      "             score=0.625\n",
      ">>step 27\n",
      "   weights -9.0   0.0   -1.7999999999999998\n",
      "             score=0.5625\n",
      ">>step 28\n",
      "   weights -8.0   6.0   -1.5999999999999999\n",
      "             score=0.6875\n",
      ">>step 29\n",
      "   weights -9.0   3.0   -1.7999999999999998\n",
      "             score=0.625\n",
      ">>step 30\n",
      "   weights -10.0   -1.0   -2.3\n",
      "             score=0.5625\n",
      ">>step 31\n",
      "   weights -9.0   5.0   -2.0999999999999996\n",
      "             score=0.625\n",
      ">>step 32\n",
      "   weights -10.0   2.0   -2.3\n",
      "             score=0.75\n",
      ">>step 33\n",
      "   weights -9.0   5.0   -1.1999999999999997\n",
      "             score=0.5625\n",
      ">>step 34\n",
      "   weights -10.0   2.0   -1.3999999999999997\n",
      "             score=0.75\n",
      ">>step 35\n",
      "   weights -9.0   5.0   -0.2999999999999996\n",
      "             score=0.6875\n",
      ">>step 36\n",
      "   weights -10.0   2.0   -0.4999999999999996\n",
      "             score=0.75\n",
      ">>step 37\n",
      "   weights -9.0   5.0   0.6000000000000005\n",
      "             score=0.6875\n",
      ">>step 38\n",
      "   weights -10.0   2.0   0.4000000000000005\n",
      "             score=0.6875\n",
      ">>step 39\n",
      "   weights -9.0   5.0   1.5000000000000007\n",
      "             score=0.6875\n",
      ">>step 40\n",
      "   weights -10.0   2.0   1.3000000000000007\n",
      "             score=0.75\n",
      ">>step 41\n",
      "   weights -9.0   5.0   2.400000000000001\n",
      "             score=0.625\n",
      ">>step 42\n",
      "   weights -10.0   2.0   2.2000000000000006\n",
      "             score=0.75\n",
      ">>step 43\n",
      "   weights -9.0   5.0   3.3000000000000007\n",
      "             score=0.625\n",
      ">>step 44\n",
      "   weights -10.0   2.0   3.1000000000000005\n",
      "             score=0.6875\n",
      ">>step 45\n",
      "   weights -9.0   5.0   4.200000000000001\n",
      "             score=0.5625\n",
      ">>step 46\n",
      "   weights -10.0   2.0   4.000000000000001\n",
      "             score=0.8125\n",
      ">>step 47\n",
      "   weights -11.0   -2.0   3.500000000000001\n",
      "             score=0.5625\n",
      ">>step 48\n",
      "   weights -10.0   4.0   3.700000000000001\n",
      "             score=0.625\n",
      ">>step 49\n",
      "   weights -11.0   1.0   3.500000000000001\n",
      "             score=0.5625\n",
      ">>step 50\n",
      "   weights -10.0   7.0   3.700000000000001\n",
      "             score=0.5625\n",
      ">>step 51\n",
      "   weights -11.0   4.0   3.500000000000001\n",
      "             score=0.75\n",
      ">>step 52\n",
      "   weights -12.0   1.0   3.3000000000000007\n",
      "             score=0.5625\n",
      ">>step 53\n",
      "   weights -11.0   7.0   3.500000000000001\n",
      "             score=0.5625\n",
      ">>step 54\n",
      "   weights -12.0   4.0   3.3000000000000007\n",
      "             score=0.75\n",
      ">>step 55\n",
      "   weights -13.0   1.0   3.1000000000000005\n",
      "             score=0.5625\n",
      ">>step 56\n",
      "   weights -12.0   7.0   3.3000000000000007\n",
      "             score=0.625\n",
      ">>step 57\n",
      "   weights -13.0   4.0   3.1000000000000005\n",
      "             score=0.75\n",
      ">>step 58\n",
      "   weights -14.0   0.0   2.6000000000000005\n",
      "             score=0.5625\n",
      ">>step 59\n",
      "   weights -13.0   6.0   2.8000000000000007\n",
      "             score=0.6875\n",
      ">>step 60\n",
      "   weights -14.0   3.0   2.6000000000000005\n",
      "             score=0.75\n",
      ">>step 61\n",
      "   weights -13.0   6.0   3.7000000000000006\n",
      "             score=0.6875\n",
      ">>step 62\n",
      "   weights -14.0   3.0   3.5000000000000004\n",
      "             score=0.6875\n",
      ">>step 63\n",
      "   weights -13.0   6.0   4.6000000000000005\n",
      "             score=0.625\n",
      ">>step 64\n",
      "   weights -14.0   3.0   4.4\n",
      "             score=0.6875\n",
      ">>step 65\n",
      "   weights -15.0   -1.0   3.9000000000000004\n",
      "             score=0.5625\n",
      ">>step 66\n",
      "   weights -14.0   5.0   4.1000000000000005\n",
      "             score=0.75\n",
      ">>step 67\n",
      "   weights -15.0   2.0   3.9000000000000004\n",
      "             score=0.625\n",
      ">>step 68\n",
      "   weights -14.0   8.0   4.1000000000000005\n",
      "             score=0.625\n",
      ">>step 69\n",
      "   weights -15.0   5.0   3.9000000000000004\n",
      "             score=0.75\n",
      ">>step 70\n",
      "   weights -16.0   2.0   3.7\n",
      "             score=0.5625\n",
      ">>step 71\n",
      "   weights -15.0   8.0   3.9000000000000004\n",
      "             score=0.6875\n",
      ">>step 72\n",
      "   weights -16.0   5.0   3.7\n",
      "             score=0.75\n",
      ">>step 73\n",
      "   weights -17.0   1.0   3.2\n",
      "             score=0.5625\n",
      ">>step 74\n",
      "   weights -16.0   7.0   3.4000000000000004\n",
      "             score=0.6875\n",
      ">>step 75\n",
      "   weights -17.0   4.0   3.2\n",
      "             score=0.6875\n",
      ">>step 76\n",
      "   weights -18.0   0.0   2.7\n",
      "             score=0.5625\n",
      ">>step 77\n",
      "   weights -17.0   6.0   2.9000000000000004\n",
      "             score=0.6875\n",
      ">>step 78\n",
      "   weights -18.0   3.0   2.7\n",
      "             score=0.75\n",
      ">>step 79\n",
      "   weights -17.0   6.0   3.8000000000000003\n",
      "             score=0.75\n",
      ">>step 80\n",
      "   weights -18.0   3.0   3.6\n",
      "             score=0.75\n",
      ">>step 81\n",
      "   weights -17.0   6.0   4.7\n",
      "             score=0.75\n",
      ">>step 82\n",
      "   weights -18.0   3.0   4.5\n",
      "             score=0.75\n",
      ">>step 83\n",
      "   weights -17.0   6.0   5.6\n",
      "             score=0.75\n",
      ">>step 84\n",
      "   weights -18.0   3.0   5.3999999999999995\n",
      "             score=0.75\n",
      ">>step 85\n",
      "   weights -17.0   6.0   6.5\n",
      "             score=0.6875\n",
      ">>step 86\n",
      "   weights -18.0   3.0   6.3\n",
      "             score=0.6875\n",
      ">>step 87\n",
      "   weights -17.0   6.0   7.4\n",
      "             score=0.625\n",
      ">>step 88\n",
      "   weights -18.0   3.0   7.2\n",
      "             score=0.75\n",
      ">>step 89\n",
      "   weights -17.0   6.0   8.3\n",
      "             score=0.625\n",
      ">>step 90\n",
      "   weights -18.0   3.0   8.100000000000001\n",
      "             score=0.8125\n",
      ">>step 91\n",
      "   weights -17.0   6.0   9.200000000000001\n",
      "             score=0.5625\n",
      ">>step 92\n",
      "   weights -18.0   3.0   9.000000000000002\n",
      "             score=0.8125\n",
      ">>step 93\n",
      "   weights -19.0   2.0   7.300000000000002\n",
      "             score=0.625\n",
      ">>step 94\n",
      "   weights -18.0   8.0   7.500000000000002\n",
      "             score=0.625\n",
      ">>step 95\n",
      "   weights -19.0   5.0   7.300000000000002\n",
      "             score=0.8125\n",
      ">>step 96\n",
      "   weights -20.0   1.0   6.800000000000002\n",
      "             score=0.5625\n",
      ">>step 97\n",
      "   weights -19.0   7.0   7.000000000000002\n",
      "             score=0.75\n",
      ">>step 98\n",
      "   weights -20.0   4.0   6.800000000000002\n",
      "             score=0.75\n",
      ">>step 99\n",
      "   weights -19.0   7.0   7.900000000000002\n",
      "             score=0.625\n",
      ">>step 100\n",
      "   weights -20.0   4.0   7.700000000000002\n",
      "             score=0.8125\n",
      ">>step 101\n",
      "   weights -19.0   6.0   9.200000000000003\n",
      "             score=0.6875\n",
      ">>step 102\n",
      "   weights -20.0   3.0   9.000000000000004\n",
      "             score=0.6875\n",
      ">>step 103\n",
      "   weights -19.0   9.0   9.200000000000003\n",
      "             score=0.5625\n",
      ">>step 104\n",
      "   weights -20.0   6.0   9.000000000000004\n",
      "             score=0.75\n",
      ">>step 105\n",
      "   weights -21.0   2.0   8.500000000000004\n",
      "             score=0.625\n",
      ">>step 106\n",
      "   weights -20.0   8.0   8.700000000000003\n",
      "             score=0.625\n",
      ">>step 107\n",
      "   weights -21.0   5.0   8.500000000000004\n",
      "             score=0.8125\n",
      ">>step 108\n",
      "   weights -22.0   1.0   8.000000000000004\n",
      "             score=0.5625\n",
      ">>step 109\n",
      "   weights -21.0   7.0   8.200000000000003\n",
      "             score=0.75\n",
      ">>step 110\n",
      "   weights -22.0   4.0   8.000000000000004\n",
      "             score=0.75\n",
      ">>step 111\n",
      "   weights -21.0   7.0   9.100000000000003\n",
      "             score=0.6875\n",
      ">>step 112\n",
      "   weights -22.0   4.0   8.900000000000004\n",
      "             score=0.75\n",
      ">>step 113\n",
      "   weights -21.0   7.0   10.000000000000004\n",
      "             score=0.625\n",
      ">>step 114\n",
      "   weights -22.0   4.0   9.800000000000004\n",
      "             score=0.875\n",
      ">>step 115\n",
      "   weights -23.0   -1.0   8.800000000000004\n",
      "             score=0.5625\n",
      ">>step 116\n",
      "   weights -22.0   5.0   9.000000000000004\n",
      "             score=0.8125\n",
      ">>step 117\n",
      "   weights -23.0   1.0   8.500000000000004\n",
      "             score=0.5625\n",
      ">>step 118\n",
      "   weights -22.0   7.0   8.700000000000003\n",
      "             score=0.75\n",
      ">>step 119\n",
      "   weights -23.0   4.0   8.500000000000004\n",
      "             score=0.75\n",
      ">>step 120\n",
      "   weights -22.0   7.0   9.600000000000003\n",
      "             score=0.6875\n",
      ">>step 121\n",
      "   weights -23.0   4.0   9.400000000000004\n",
      "             score=0.75\n",
      ">>step 122\n",
      "   weights -22.0   7.0   10.500000000000004\n",
      "             score=0.6875\n",
      ">>step 123\n",
      "   weights -23.0   4.0   10.300000000000004\n",
      "             score=0.875\n",
      ">>step 124\n",
      "   weights -24.0   -1.0   9.300000000000004\n",
      "             score=0.5625\n",
      ">>step 125\n",
      "   weights -23.0   5.0   9.500000000000004\n",
      "             score=0.8125\n",
      ">>step 126\n",
      "   weights -24.0   1.0   9.000000000000004\n",
      "             score=0.5625\n",
      ">>step 127\n",
      "   weights -23.0   7.0   9.200000000000003\n",
      "             score=0.8125\n",
      ">>step 128\n",
      "   weights -24.0   3.0   8.700000000000003\n",
      "             score=0.6875\n",
      ">>step 129\n",
      "   weights -23.0   9.0   8.900000000000002\n",
      "             score=0.625\n",
      ">>step 130\n",
      "   weights -24.0   6.0   8.700000000000003\n",
      "             score=0.8125\n",
      ">>step 131\n",
      "   weights -25.0   2.0   8.200000000000003\n",
      "             score=0.5625\n",
      ">>step 132\n",
      "   weights -24.0   8.0   8.400000000000002\n",
      "             score=0.75\n",
      ">>step 133\n",
      "   weights -25.0   5.0   8.200000000000003\n",
      "             score=0.75\n",
      ">>step 134\n",
      "   weights -24.0   8.0   9.300000000000002\n",
      "             score=0.75\n",
      ">>step 135\n",
      "   weights -25.0   5.0   9.100000000000003\n",
      "             score=0.8125\n",
      ">>step 136\n",
      "   weights -24.0   7.0   10.600000000000003\n",
      "             score=0.75\n",
      ">>step 137\n",
      "   weights -25.0   3.0   10.100000000000003\n",
      "             score=0.6875\n",
      ">>step 138\n",
      "   weights -24.0   9.0   10.300000000000002\n",
      "             score=0.625\n",
      ">>step 139\n",
      "   weights -25.0   6.0   10.100000000000003\n",
      "             score=0.8125\n",
      ">>step 140\n",
      "   weights -26.0   2.0   9.600000000000003\n",
      "             score=0.5625\n",
      ">>step 141\n",
      "   weights -25.0   8.0   9.800000000000002\n",
      "             score=0.75\n",
      ">>step 142\n",
      "   weights -26.0   5.0   9.600000000000003\n",
      "             score=0.75\n",
      ">>step 143\n",
      "   weights -25.0   8.0   10.700000000000003\n",
      "             score=0.6875\n",
      ">>step 144\n",
      "   weights -26.0   5.0   10.500000000000004\n",
      "             score=0.8125\n",
      ">>step 145\n",
      "   weights -25.0   7.0   12.000000000000004\n",
      "             score=0.75\n",
      ">>step 146\n",
      "   weights -26.0   3.0   11.500000000000004\n",
      "             score=0.625\n",
      ">>step 147\n",
      "   weights -25.0   9.0   11.700000000000003\n",
      "             score=0.625\n",
      ">>step 148\n",
      "   weights -26.0   6.0   11.500000000000004\n",
      "             score=0.8125\n",
      ">>step 149\n",
      "   weights -27.0   2.0   11.000000000000004\n",
      "             score=0.5625\n",
      ">>step 150\n",
      "   weights -26.0   8.0   11.200000000000003\n",
      "             score=0.6875\n",
      ">>step 151\n",
      "   weights -27.0   5.0   11.000000000000004\n",
      "             score=0.8125\n",
      ">>step 152\n",
      "   weights -26.0   7.0   12.500000000000004\n",
      "             score=0.75\n",
      ">>step 153\n",
      "   weights -27.0   3.0   12.000000000000004\n",
      "             score=0.5625\n",
      ">>step 154\n",
      "   weights -26.0   9.0   12.200000000000003\n",
      "             score=0.625\n",
      ">>step 155\n",
      "   weights -27.0   6.0   12.000000000000004\n",
      "             score=0.8125\n",
      ">>step 156\n",
      "   weights -28.0   2.0   11.500000000000004\n",
      "             score=0.5625\n",
      ">>step 157\n",
      "   weights -27.0   8.0   11.700000000000003\n",
      "             score=0.75\n",
      ">>step 158\n",
      "   weights -28.0   4.0   11.200000000000003\n",
      "             score=0.6875\n",
      ">>step 159\n",
      "   weights -27.0   10.0   11.400000000000002\n",
      "             score=0.625\n",
      ">>step 160\n",
      "   weights -28.0   7.0   11.200000000000003\n",
      "             score=0.8125\n",
      ">>step 161\n",
      "   weights -29.0   3.0   10.700000000000003\n",
      "             score=0.625\n",
      ">>step 162\n",
      "   weights -28.0   9.0   10.900000000000002\n",
      "             score=0.75\n",
      ">>step 163\n",
      "   weights -29.0   6.0   10.700000000000003\n",
      "             score=0.75\n",
      ">>step 164\n",
      "   weights -30.0   2.0   10.200000000000003\n",
      "             score=0.5625\n",
      ">>step 165\n",
      "   weights -29.0   8.0   10.400000000000002\n",
      "             score=0.8125\n",
      ">>step 166\n",
      "   weights -30.0   4.0   9.900000000000002\n",
      "             score=0.75\n",
      ">>step 167\n",
      "   weights -29.0   10.0   10.100000000000001\n",
      "             score=0.75\n",
      ">>step 168\n",
      "   weights -30.0   7.0   9.900000000000002\n",
      "             score=0.75\n",
      ">>step 169\n",
      "   weights -31.0   3.0   9.400000000000002\n",
      "             score=0.5625\n",
      ">>step 170\n",
      "   weights -30.0   9.0   9.600000000000001\n",
      "             score=0.8125\n",
      ">>step 171\n",
      "   weights -31.0   5.0   9.100000000000001\n",
      "             score=0.75\n",
      ">>step 172\n",
      "   weights -30.0   8.0   10.200000000000001\n",
      "             score=0.8125\n",
      ">>step 173\n",
      "   weights -31.0   4.0   9.700000000000001\n",
      "             score=0.625\n",
      ">>step 174\n",
      "   weights -30.0   10.0   9.9\n",
      "             score=0.75\n",
      ">>step 175\n",
      "   weights -31.0   7.0   9.700000000000001\n",
      "             score=0.75\n",
      ">>step 176\n",
      "   weights -32.0   3.0   9.200000000000001\n",
      "             score=0.5625\n",
      ">>step 177\n",
      "   weights -31.0   9.0   9.4\n",
      "             score=0.8125\n",
      ">>step 178\n",
      "   weights -32.0   5.0   8.9\n",
      "             score=0.6875\n",
      ">>step 179\n",
      "   weights -31.0   11.0   9.1\n",
      "             score=0.75\n",
      ">>step 180\n",
      "   weights -32.0   8.0   8.9\n",
      "             score=0.75\n",
      ">>step 181\n",
      "   weights -33.0   4.0   8.4\n",
      "             score=0.5625\n",
      ">>step 182\n",
      "   weights -32.0   10.0   8.6\n",
      "             score=0.8125\n",
      ">>step 183\n",
      "   weights -33.0   6.0   8.1\n",
      "             score=0.75\n",
      ">>step 184\n",
      "   weights -32.0   9.0   9.2\n",
      "             score=0.75\n",
      ">>step 185\n",
      "   weights -33.0   5.0   8.7\n",
      "             score=0.6875\n",
      ">>step 186\n",
      "   weights -32.0   11.0   8.899999999999999\n",
      "             score=0.75\n",
      ">>step 187\n",
      "   weights -33.0   8.0   8.7\n",
      "             score=0.6875\n",
      ">>step 188\n",
      "   weights -34.0   4.0   8.2\n",
      "             score=0.5625\n",
      ">>step 189\n",
      "   weights -33.0   10.0   8.399999999999999\n",
      "             score=0.75\n",
      ">>step 190\n",
      "   weights -34.0   6.0   7.899999999999999\n",
      "             score=0.75\n",
      ">>step 191\n",
      "   weights -33.0   9.0   8.999999999999998\n",
      "             score=0.75\n",
      ">>step 192\n",
      "   weights -34.0   5.0   8.499999999999998\n",
      "             score=0.75\n",
      ">>step 193\n",
      "   weights -33.0   11.0   8.699999999999998\n",
      "             score=0.75\n",
      ">>step 194\n",
      "   weights -34.0   8.0   8.499999999999998\n",
      "             score=0.625\n",
      ">>step 195\n",
      "   weights -35.0   4.0   7.999999999999998\n",
      "             score=0.5625\n",
      ">>step 196\n",
      "   weights -34.0   10.0   8.199999999999998\n",
      "             score=0.75\n",
      ">>step 197\n",
      "   weights -35.0   6.0   7.6999999999999975\n",
      "             score=0.75\n",
      ">>step 198\n",
      "   weights -34.0   9.0   8.799999999999997\n",
      "             score=0.75\n",
      ">>step 199\n",
      "   weights -35.0   5.0   8.299999999999997\n",
      "             score=0.6875\n",
      "-----------------POCKET REPORT-----------------\n",
      "pocket scores: [0, 0.4375, 0.5625, 0.6875, 0.75, 0.8125, 0.875]\n",
      "max score: 0.875\n",
      "index: (array([114, 123], dtype=int64), array([0, 0], dtype=int64))\n",
      "the weights of index 114 :\n",
      "[-23.0, -1.0, 8.800000000000004]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ------------------------------------------------------\n",
    "x_data1 = [\n",
    "    [3, 0.2],\n",
    "    [1, 0.3],\n",
    "    [4, 0.5],\n",
    "    [2, 0.7],\n",
    "    [0, 1],\n",
    "    [1, 1.2],\n",
    "    [1, 1.7],\n",
    "    [6, 0.2],\n",
    "    [7, 0.3],\n",
    "    [6, 0.7],\n",
    "    [3, 1.1],\n",
    "    [2, 1.5],\n",
    "    [4, 1.7],\n",
    "    [2, 1.9],\n",
    "]\n",
    "y_data1 = [-1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1]\n",
    "y_data1 = np.array(y_data1)\n",
    "\n",
    "x_data1 = np.array(x_data1)\n",
    "x01 = np.ones(14)\n",
    "x01 = x01.reshape(14, 1)\n",
    "x_with_bias1 = np.concatenate((x01, x_data1), axis=1)\n",
    "\n",
    "\n",
    "x_data2 = [\n",
    "    [3, 0.2],\n",
    "    [1, 0.3],\n",
    "    [4, 0.5],\n",
    "    [2, 0.7],\n",
    "    [0, 1],\n",
    "    [1, 1.2],\n",
    "    [1, 1.7],\n",
    "    [6, 0.2],\n",
    "    [7, 0.3],\n",
    "    [6, 0.7],\n",
    "    [3, 1.1],\n",
    "    [2, 1.5],\n",
    "    [4, 1.7],\n",
    "    [2, 1.9],\n",
    "    [5, 1],\n",
    "    [3, 1.5],\n",
    "]\n",
    "y_data2 = [-1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1, -1, -1]\n",
    "y_data2 = np.array(y_data2)\n",
    "\n",
    "x_data2 = np.array(x_data2)\n",
    "x0 = np.ones(16)\n",
    "x0 = x0.reshape(16, 1)\n",
    "x_with_bias2 = np.concatenate((x0, x_data2), axis=1)\n",
    "# ------------------------------------------------------\n",
    "#\n",
    "# OOP\n",
    "#\n",
    "\n",
    "\n",
    "class Perceptron2:\n",
    "    def __init__(self, learning_rate, iteration, xx, yy):\n",
    "        self.learn = learning_rate\n",
    "        self.itr = iteration\n",
    "        self.x_data = xx\n",
    "        self.y_data = yy\n",
    "\n",
    "    def predict(self, w0, w1, w2):\n",
    "        self.initial_weights = [w0, w1, w2]\n",
    "        self.predicted = []\n",
    "        for i in self.x_data:\n",
    "            wx0 = i[0] * w0\n",
    "            wx1 = i[1] * w1\n",
    "            wx2 = i[2] * w2\n",
    "            summ = wx0 + wx1 + wx2\n",
    "            # print(summ)\n",
    "            if summ >= 0:\n",
    "                summ = 1\n",
    "                self.predicted.append(summ)\n",
    "            elif summ < 0:\n",
    "                summ = -1\n",
    "                self.predicted.append(summ)\n",
    "        return self.predicted\n",
    "\n",
    "    def update_weight(self):\n",
    "        w0, w1, w2 = self.initial_weights\n",
    "        ypred = np.array(self.predicted)\n",
    "        ypred = ypred.reshape(ypred.shape[0], 1)\n",
    "        yy0 = self.y_data.reshape(self.y_data.shape[0], 1)\n",
    "        y = np.concatenate((yy0, ypred), axis=1)\n",
    "        for i in range(len(y)):\n",
    "            A = y[i][0] != y[i][1]\n",
    "            if A == True:\n",
    "                self.mis_index = i\n",
    "                # print(self.mis_index,self.x_data[self.mis_index][0])\n",
    "                w0_new = w0 + (\n",
    "                    self.x_data[self.mis_index][0] * yy0[self.mis_index][0] * self.learn\n",
    "                )\n",
    "                w1_new = w1 + (\n",
    "                    self.x_data[self.mis_index][1] * yy0[self.mis_index][0] * self.learn\n",
    "                )\n",
    "                w2_new = w2 + (\n",
    "                    self.x_data[self.mis_index][2] * yy0[self.mis_index][0] * self.learn\n",
    "                )\n",
    "                break\n",
    "        # print(self.sto,self.y_data,sep='\\n')\n",
    "        # print(w0_new,w1_new,w2_new)\n",
    "        return w0_new, w1_new, w2_new\n",
    "\n",
    "    def do2(self, w, ww, www):\n",
    "        predict = self.predict(w, ww, www)\n",
    "        wn1, wn2, wn3 = self.update_weight()\n",
    "        return wn1, wn2, wn3\n",
    "\n",
    "    def fit(self, init_w0, init_w1, init_w2):\n",
    "        epoch = 0\n",
    "        w0, w1, w2 = init_w0, init_w1, init_w2\n",
    "        self.state = []\n",
    "        while epoch < self.itr:\n",
    "            try:\n",
    "                print(\">>step {}\".format(epoch))\n",
    "                print(\"   weights {}   {}   {}\".format(w0, w1, w2))\n",
    "                w0, w1, w2 = self.do2(w0, w1, w2)\n",
    "                score = self.accuracy()\n",
    "                print(\"             score={}\".format(score))\n",
    "                self.state.append([score, epoch, [w0, w1, w2]])\n",
    "                epoch += 1\n",
    "            except:\n",
    "                print(\"score: {}\".format(self.accuracy()))\n",
    "                print(\"----\\n\\n end of optimization \\n\\n----\")\n",
    "                break\n",
    "        self.state = np.array(self.state, dtype=\"object\")\n",
    "        return self.state\n",
    "\n",
    "    def accuracy(self):\n",
    "        # acc\n",
    "        self.y_data = self.y_data.reshape(self.y_data.shape[0], 1)\n",
    "        ypred = np.array(self.predicted)\n",
    "        ypred = ypred.reshape(ypred.shape[0], 1)\n",
    "        yy = np.concatenate((self.y_data, ypred), axis=1)\n",
    "        sc = []\n",
    "        score = 0\n",
    "        for i, j in yy:\n",
    "            if i == j:\n",
    "                score += 1\n",
    "        self.sc = score / len(yy)\n",
    "        return self.sc\n",
    "\n",
    "    def pocket(self, init_w0, init_w1, init_w2):\n",
    "        # pocket\n",
    "        epoch = 0\n",
    "        w0, w1, w2 = init_w0, init_w1, init_w2\n",
    "        self.state = []\n",
    "        pocket_score = [0]\n",
    "        while epoch < self.itr:\n",
    "            try:\n",
    "                w0, w1, w2 = self.do2(w0, w1, w2)\n",
    "                score = self.accuracy()\n",
    "                if len(self.state) > 0:\n",
    "                    previous_score = self.state[-1][0]\n",
    "                    if previous_score > max(pocket_score):\n",
    "                        pocket_score.append(previous_score)\n",
    "\n",
    "                self.state.append([score, epoch, [w0, w1, w2]])\n",
    "                epoch += 1\n",
    "            except:\n",
    "\n",
    "                break\n",
    "\n",
    "        self.state = np.array(self.state, dtype=\"object\")\n",
    "        return self.state, pocket_score\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "instancee = Perceptron2(1, 200, x_with_bias2, y_data2)\n",
    "stat = instancee.fit(0, 0, 0)\n",
    "stat, pocket = instancee.pocket(0, 0, 0)\n",
    "\n",
    "index_num = 114\n",
    "print(\n",
    "    \"-----------------POCKET REPORT-----------------\\npocket scores: {}\".format(pocket),\n",
    "    \"max score: {}\".format(max(stat[:, 0])),\n",
    "    \"index: {}\".format(np.where(stat == max(stat[:, 0]))),\n",
    "    \"the weights of index {} :\".format(index_num),\n",
    "    stat[index_num, 2],\n",
    "    sep=\"\\n\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b385d4",
   "metadata": {},
   "source": [
    "# POCKET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9552d52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------POCKET REPORT-----------------\n",
      "\n",
      "pocket scores: [0, 0.4375, 0.5625, 0.6875, 0.75]\n",
      "max score: 0.750\n",
      "the weights of index 1997  where max score is happend :\n",
      "[-42.0, 11.0, -5.199999999999836]\n",
      "max score epoch: 1997\n",
      "predicted:\n",
      " [-1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, -1, -1, -1, -1] \n",
      "True valu\n",
      " [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# ---------------\n",
    "# POCKET\n",
    "# ---------------\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------\n",
    "x_data2 = [\n",
    "    [3, 0.2],\n",
    "    [1, 0.3],\n",
    "    [4, 0.5],\n",
    "    [2, 0.7],\n",
    "    [0, 1],\n",
    "    [1, 1.2],\n",
    "    [1, 1.7],\n",
    "    [5, 1],\n",
    "    [3, 1.5],\n",
    "    [6, 0.2],\n",
    "    [7, 0.3],\n",
    "    [6, 0.7],\n",
    "    [3, 1.1],\n",
    "    [2, 1.5],\n",
    "    [4, 1.7],\n",
    "    [2, 1.9],\n",
    "]\n",
    "y_data2 = [\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "]\n",
    "y_data2 = np.array(y_data2)\n",
    "\n",
    "x_data2 = np.array(x_data2)\n",
    "x0 = np.ones(16)\n",
    "x0 = x0.reshape(16, 1)\n",
    "x_with_bias2 = np.concatenate((x0, x_data2), axis=1)\n",
    "# ------------------------------------------------------\n",
    "#\n",
    "# OOP\n",
    "#\n",
    "\n",
    "\n",
    "class POCKET:\n",
    "    def __init__(self, learning_rate, iteration, xx, yy):\n",
    "        self.learn = learning_rate\n",
    "        self.itr = iteration\n",
    "        self.x_data = xx\n",
    "        self.y_data = yy\n",
    "\n",
    "    def predict(self, w0, w1, w2):\n",
    "        self.initial_weights = [w0, w1, w2]\n",
    "        self.predicted = []\n",
    "        for i in self.x_data:\n",
    "            wx0 = i[0] * w0\n",
    "            wx1 = i[1] * w1\n",
    "            wx2 = i[2] * w2\n",
    "            summ = wx0 + wx1 + wx2\n",
    "            # print(summ)\n",
    "            if summ >= 0:\n",
    "                summ = 1\n",
    "                self.predicted.append(summ)\n",
    "            elif summ < 0:\n",
    "                summ = -1\n",
    "                self.predicted.append(summ)\n",
    "        return self.predicted\n",
    "\n",
    "    def update_weight(self):\n",
    "        w0, w1, w2 = self.initial_weights\n",
    "        ypred = np.array(self.predicted)\n",
    "        ypred = ypred.reshape(ypred.shape[0], 1)\n",
    "        yy0 = self.y_data.reshape(self.y_data.shape[0], 1)\n",
    "        y = np.concatenate((yy0, ypred), axis=1)\n",
    "        for i in range(len(y)):\n",
    "            A = y[i][0] != y[i][1]\n",
    "            if A == True:\n",
    "                self.mis_index = i\n",
    "                # print(self.mis_index,self.x_data[self.mis_index][0])\n",
    "                w0_new = w0 + (\n",
    "                    self.x_data[self.mis_index][0] * yy0[self.mis_index][0] * self.learn\n",
    "                )\n",
    "                w1_new = w1 + (\n",
    "                    self.x_data[self.mis_index][1] * yy0[self.mis_index][0] * self.learn\n",
    "                )\n",
    "                w2_new = w2 + (\n",
    "                    self.x_data[self.mis_index][2] * yy0[self.mis_index][0] * self.learn\n",
    "                )\n",
    "                break\n",
    "        # print(self.sto,self.y_data,sep='\\n')\n",
    "        # print(w0_new,w1_new,w2_new)\n",
    "        return w0_new, w1_new, w2_new\n",
    "\n",
    "    def do2(self, w, ww, www):\n",
    "        predict = self.predict(w, ww, www)\n",
    "        wn1, wn2, wn3 = self.update_weight()\n",
    "        return wn1, wn2, wn3\n",
    "\n",
    "    def accuracy(self):\n",
    "        # acc\n",
    "        self.y_data = self.y_data.reshape(self.y_data.shape[0], 1)\n",
    "        ypred = np.array(self.predicted)\n",
    "        ypred = ypred.reshape(ypred.shape[0], 1)\n",
    "        yy = np.concatenate((self.y_data, ypred), axis=1)\n",
    "        score = 0\n",
    "        for i, j in yy:\n",
    "            if i == j:\n",
    "                score += 1\n",
    "        self.sc = score / len(yy)\n",
    "        return self.sc\n",
    "\n",
    "    def pocket(self, weight0, weight1, weight2):\n",
    "        # pocket\n",
    "        epoch = 0\n",
    "        self.state = []\n",
    "        pocket_score = [0]\n",
    "        while epoch < self.itr:\n",
    "            try:\n",
    "                weight0, weight1, weight2 = self.do2(weight0, weight1, weight2)\n",
    "                score = self.accuracy()\n",
    "                if len(self.state) > 0:\n",
    "                    previous_score = self.state[-1][0]\n",
    "                    if previous_score > max(pocket_score):\n",
    "                        pocket_score.append(previous_score)\n",
    "\n",
    "                self.state.append([score, epoch, [weight0, weight1, weight2]])\n",
    "                epoch += 1\n",
    "            except:\n",
    "\n",
    "                break\n",
    "\n",
    "        self.state = np.array(self.state, dtype=\"object\")\n",
    "        return self.state, pocket_score\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "instancee = POCKET(1, 2000, x_with_bias2, y_data2)  # (learning_rate,iteration,x,y)\n",
    "stat, pocket = instancee.pocket(\n",
    "    0, 0, 0\n",
    ")  # (initialweight0,initialweight1,initialweight2)\n",
    "\n",
    "s, _ = np.where(stat == max(stat[:, 0]))\n",
    "index_num = s[-1]\n",
    "\n",
    "print(\n",
    "    \"-----------------POCKET REPORT-----------------\\n\\npocket scores: {}\".format(\n",
    "        pocket\n",
    "    ),\n",
    "    \"max score: {:.3f}\".format(max(stat[:, 0])),\n",
    "    \"the weights of index {}  where max score is happend :\".format(index_num),\n",
    "    \"{}\".format(stat[index_num, 2]),\n",
    "    \"max score epoch: {}\".format(index_num),\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "print(\n",
    "    \"predicted:\\n\",\n",
    "    list(instancee.predict(-42, 11, -5.19)),\n",
    "    \"\\nTrue valu\\n\",\n",
    "    list(y_data2),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e03a97",
   "metadata": {},
   "source": [
    "----\n",
    "# NO 2 - same thing in different procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e3319c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====marhale==== 0\n",
      "vaznHa  : 0 0 0\n",
      "====marhale==== 1\n",
      "vaznHa  :-1.00 | -3.00 | -0.20\n",
      "\n",
      "====marhale==== 2\n",
      "vaznHa  :0.00 | 3.00 | 0.00\n",
      "\n",
      "====marhale==== 3\n",
      "vaznHa  :-1.00 | 0.00 | -0.20\n",
      "\n",
      "====marhale==== 4\n",
      "vaznHa  :0.00 | 6.00 | 0.00\n",
      "\n",
      "====marhale==== 5\n",
      "vaznHa  :-1.00 | 3.00 | -0.20\n",
      "\n",
      "====marhale==== 6\n",
      "vaznHa  :-2.00 | 0.00 | -0.40\n",
      "\n",
      "====marhale==== 7\n",
      "vaznHa  :-1.00 | 6.00 | -0.20\n",
      "\n",
      "====marhale==== 8\n",
      "vaznHa  :-2.00 | 3.00 | -0.40\n",
      "\n",
      "====marhale==== 9\n",
      "vaznHa  :-3.00 | 0.00 | -0.60\n",
      "\n",
      "====marhale==== 10\n",
      "vaznHa  :-2.00 | 6.00 | -0.40\n",
      "\n",
      "====marhale==== 11\n",
      "vaznHa  :-3.00 | 3.00 | -0.60\n",
      "\n",
      "====marhale==== 12\n",
      "vaznHa  :-4.00 | 0.00 | -0.80\n",
      "\n",
      "====marhale==== 13\n",
      "vaznHa  :-3.00 | 6.00 | -0.60\n",
      "\n",
      "====marhale==== 14\n",
      "vaznHa  :-4.00 | 3.00 | -0.80\n",
      "\n",
      "====marhale==== 15\n",
      "vaznHa  :-5.00 | 0.00 | -1.00\n",
      "\n",
      "====marhale==== 16\n",
      "vaznHa  :-4.00 | 6.00 | -0.80\n",
      "\n",
      "====marhale==== 17\n",
      "vaznHa  :-5.00 | 3.00 | -1.00\n",
      "\n",
      "====marhale==== 18\n",
      "vaznHa  :-6.00 | 0.00 | -1.20\n",
      "\n",
      "====marhale==== 19\n",
      "vaznHa  :-5.00 | 6.00 | -1.00\n",
      "\n",
      "====marhale==== 20\n",
      "vaznHa  :-6.00 | 3.00 | -1.20\n",
      "\n",
      "====marhale==== 21\n",
      "vaznHa  :-7.00 | 0.00 | -1.40\n",
      "\n",
      "====marhale==== 22\n",
      "vaznHa  :-6.00 | 6.00 | -1.20\n",
      "\n",
      "====marhale==== 23\n",
      "vaznHa  :-7.00 | 3.00 | -1.40\n",
      "\n",
      "====marhale==== 24\n",
      "vaznHa  :-8.00 | 0.00 | -1.60\n",
      "\n",
      "====marhale==== 25\n",
      "vaznHa  :-7.00 | 6.00 | -1.40\n",
      "\n",
      "====marhale==== 26\n",
      "vaznHa  :-8.00 | 3.00 | -1.60\n",
      "\n",
      "====marhale==== 27\n",
      "vaznHa  :-9.00 | 0.00 | -1.80\n",
      "\n",
      "====marhale==== 28\n",
      "vaznHa  :-8.00 | 6.00 | -1.60\n",
      "\n",
      "====marhale==== 29\n",
      "vaznHa  :-9.00 | 3.00 | -1.80\n",
      "\n",
      "====marhale==== 30\n",
      "vaznHa  :-10.00 | -1.00 | -2.30\n",
      "\n",
      "====marhale==== 31\n",
      "vaznHa  :-9.00 | 5.00 | -2.10\n",
      "\n",
      "====marhale==== 32\n",
      "vaznHa  :-10.00 | 2.00 | -2.30\n",
      "\n",
      "====marhale==== 33\n",
      "vaznHa  :-9.00 | 5.00 | -1.20\n",
      "\n",
      "====marhale==== 34\n",
      "vaznHa  :-10.00 | 2.00 | -1.40\n",
      "\n",
      "====marhale==== 35\n",
      "vaznHa  :-9.00 | 5.00 | -0.30\n",
      "\n",
      "====marhale==== 36\n",
      "vaznHa  :-10.00 | 2.00 | -0.50\n",
      "\n",
      "====marhale==== 37\n",
      "vaznHa  :-9.00 | 5.00 | 0.60\n",
      "\n",
      "====marhale==== 38\n",
      "vaznHa  :-10.00 | 2.00 | 0.40\n",
      "\n",
      "====marhale==== 39\n",
      "vaznHa  :-9.00 | 5.00 | 1.50\n",
      "\n",
      "====marhale==== 40\n",
      "vaznHa  :-10.00 | 2.00 | 1.30\n",
      "\n",
      "====marhale==== 41\n",
      "vaznHa  :-9.00 | 5.00 | 2.40\n",
      "\n",
      "====marhale==== 42\n",
      "vaznHa  :-10.00 | 2.00 | 2.20\n",
      "\n",
      "====marhale==== 43\n",
      "vaznHa  :-9.00 | 5.00 | 3.30\n",
      "\n",
      "====marhale==== 44\n",
      "vaznHa  :-10.00 | 2.00 | 3.10\n",
      "\n",
      "====marhale==== 45\n",
      "vaznHa  :-9.00 | 5.00 | 4.20\n",
      "\n",
      "====marhale==== 46\n",
      "vaznHa  :-10.00 | 2.00 | 4.00\n",
      "\n",
      "====marhale==== 47\n",
      "vaznHa  :-11.00 | -2.00 | 3.50\n",
      "\n",
      "====marhale==== 48\n",
      "vaznHa  :-10.00 | 4.00 | 3.70\n",
      "\n",
      "====marhale==== 49\n",
      "vaznHa  :-11.00 | 1.00 | 3.50\n",
      "\n",
      "====marhale==== 50\n",
      "vaznHa  :-10.00 | 7.00 | 3.70\n",
      "\n",
      "====marhale==== 51\n",
      "vaznHa  :-11.00 | 4.00 | 3.50\n",
      "\n",
      "====marhale==== 52\n",
      "vaznHa  :-12.00 | 1.00 | 3.30\n",
      "\n",
      "====marhale==== 53\n",
      "vaznHa  :-11.00 | 7.00 | 3.50\n",
      "\n",
      "====marhale==== 54\n",
      "vaznHa  :-12.00 | 4.00 | 3.30\n",
      "\n",
      "====marhale==== 55\n",
      "vaznHa  :-13.00 | 1.00 | 3.10\n",
      "\n",
      "====marhale==== 56\n",
      "vaznHa  :-12.00 | 7.00 | 3.30\n",
      "\n",
      "====marhale==== 57\n",
      "vaznHa  :-13.00 | 4.00 | 3.10\n",
      "\n",
      "====marhale==== 58\n",
      "vaznHa  :-14.00 | 0.00 | 2.60\n",
      "\n",
      "====marhale==== 59\n",
      "vaznHa  :-13.00 | 6.00 | 2.80\n",
      "\n",
      "====marhale==== 60\n",
      "vaznHa  :-14.00 | 3.00 | 2.60\n",
      "\n",
      "====marhale==== 61\n",
      "vaznHa  :-13.00 | 6.00 | 3.70\n",
      "\n",
      "====marhale==== 62\n",
      "vaznHa  :-14.00 | 3.00 | 3.50\n",
      "\n",
      "====marhale==== 63\n",
      "vaznHa  :-13.00 | 6.00 | 4.60\n",
      "\n",
      "====marhale==== 64\n",
      "vaznHa  :-14.00 | 3.00 | 4.40\n",
      "\n",
      "====marhale==== 65\n",
      "vaznHa  :-15.00 | -1.00 | 3.90\n",
      "\n",
      "====marhale==== 66\n",
      "vaznHa  :-14.00 | 5.00 | 4.10\n",
      "\n",
      "====marhale==== 67\n",
      "vaznHa  :-15.00 | 2.00 | 3.90\n",
      "\n",
      "====marhale==== 68\n",
      "vaznHa  :-14.00 | 8.00 | 4.10\n",
      "\n",
      "====marhale==== 69\n",
      "vaznHa  :-15.00 | 5.00 | 3.90\n",
      "\n",
      "====marhale==== 70\n",
      "vaznHa  :-16.00 | 2.00 | 3.70\n",
      "\n",
      "====marhale==== 71\n",
      "vaznHa  :-15.00 | 8.00 | 3.90\n",
      "\n",
      "====marhale==== 72\n",
      "vaznHa  :-16.00 | 5.00 | 3.70\n",
      "\n",
      "====marhale==== 73\n",
      "vaznHa  :-17.00 | 1.00 | 3.20\n",
      "\n",
      "====marhale==== 74\n",
      "vaznHa  :-16.00 | 7.00 | 3.40\n",
      "\n",
      "====marhale==== 75\n",
      "vaznHa  :-17.00 | 4.00 | 3.20\n",
      "\n",
      "====marhale==== 76\n",
      "vaznHa  :-18.00 | 0.00 | 2.70\n",
      "\n",
      "====marhale==== 77\n",
      "vaznHa  :-17.00 | 6.00 | 2.90\n",
      "\n",
      "====marhale==== 78\n",
      "vaznHa  :-18.00 | 3.00 | 2.70\n",
      "\n",
      "====marhale==== 79\n",
      "vaznHa  :-17.00 | 6.00 | 3.80\n",
      "\n",
      "====marhale==== 80\n",
      "vaznHa  :-18.00 | 3.00 | 3.60\n",
      "\n",
      "====marhale==== 81\n",
      "vaznHa  :-17.00 | 6.00 | 4.70\n",
      "\n",
      "====marhale==== 82\n",
      "vaznHa  :-18.00 | 3.00 | 4.50\n",
      "\n",
      "====marhale==== 83\n",
      "vaznHa  :-17.00 | 6.00 | 5.60\n",
      "\n",
      "====marhale==== 84\n",
      "vaznHa  :-18.00 | 3.00 | 5.40\n",
      "\n",
      "====marhale==== 85\n",
      "vaznHa  :-17.00 | 6.00 | 6.50\n",
      "\n",
      "====marhale==== 86\n",
      "vaznHa  :-18.00 | 3.00 | 6.30\n",
      "\n",
      "====marhale==== 87\n",
      "vaznHa  :-17.00 | 6.00 | 7.40\n",
      "\n",
      "====marhale==== 88\n",
      "vaznHa  :-18.00 | 3.00 | 7.20\n",
      "\n",
      "====marhale==== 89\n",
      "vaznHa  :-17.00 | 6.00 | 8.30\n",
      "\n",
      "====marhale==== 90\n",
      "vaznHa  :-18.00 | 3.00 | 8.10\n",
      "\n",
      "====marhale==== 91\n",
      "vaznHa  :-17.00 | 6.00 | 9.20\n",
      "\n",
      "====marhale==== 92\n",
      "vaznHa  :-18.00 | 3.00 | 9.00\n",
      "\n",
      "====marhale==== 93\n",
      "vaznHa  :-19.00 | 2.00 | 7.30\n",
      "\n",
      "====marhale==== 94\n",
      "vaznHa  :-18.00 | 8.00 | 7.50\n",
      "\n",
      "====marhale==== 95\n",
      "vaznHa  :-19.00 | 5.00 | 7.30\n",
      "\n",
      "====marhale==== 96\n",
      "vaznHa  :-20.00 | 1.00 | 6.80\n",
      "\n",
      "====marhale==== 97\n",
      "vaznHa  :-19.00 | 7.00 | 7.00\n",
      "\n",
      "====marhale==== 98\n",
      "vaznHa  :-20.00 | 4.00 | 6.80\n",
      "\n",
      "====marhale==== 99\n",
      "vaznHa  :-19.00 | 7.00 | 7.90\n",
      "\n",
      "====marhale==== 100\n",
      "vaznHa  :-20.00 | 4.00 | 7.70\n",
      "\n",
      "====marhale==== 101\n",
      "vaznHa  :-19.00 | 6.00 | 9.20\n",
      "\n",
      "====marhale==== 102\n",
      "vaznHa  :-20.00 | 3.00 | 9.00\n",
      "\n",
      "====marhale==== 103\n",
      "vaznHa  :-19.00 | 9.00 | 9.20\n",
      "\n",
      "====marhale==== 104\n",
      "vaznHa  :-20.00 | 6.00 | 9.00\n",
      "\n",
      "====marhale==== 105\n",
      "vaznHa  :-21.00 | 2.00 | 8.50\n",
      "\n",
      "====marhale==== 106\n",
      "vaznHa  :-20.00 | 8.00 | 8.70\n",
      "\n",
      "====marhale==== 107\n",
      "vaznHa  :-21.00 | 5.00 | 8.50\n",
      "\n",
      "====marhale==== 108\n",
      "vaznHa  :-22.00 | 1.00 | 8.00\n",
      "\n",
      "====marhale==== 109\n",
      "vaznHa  :-21.00 | 7.00 | 8.20\n",
      "\n",
      "====marhale==== 110\n",
      "vaznHa  :-22.00 | 4.00 | 8.00\n",
      "\n",
      "====marhale==== 111\n",
      "vaznHa  :-21.00 | 7.00 | 9.10\n",
      "\n",
      "====marhale==== 112\n",
      "vaznHa  :-22.00 | 4.00 | 8.90\n",
      "\n",
      "====marhale==== 113\n",
      "vaznHa  :-21.00 | 7.00 | 10.00\n",
      "\n",
      "====marhale==== 114\n",
      "vaznHa  :-22.00 | 4.00 | 9.80\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "xData=np.array([[1 , 3 , 0.2],\n",
    "       [1 , 1 , 0.3],\n",
    "       [1 , 4 , 0.5],\n",
    "       [1 , 2 , 0.7],\n",
    "       [1 , 0 , 1. ],\n",
    "       [1 , 1 , 1.2],\n",
    "       [1 , 1 , 1.7],\n",
    "       [1 , 6 , 0.2],\n",
    "       [1 , 7 , 0.3],\n",
    "       [1 , 6 , 0.7],\n",
    "       [1 , 3 , 1.1],\n",
    "       [1 , 2 , 1.5],\n",
    "       [1 , 4 , 1.7],\n",
    "       [1 , 2 , 1.9]])\n",
    "yData=np.array([-1,-1,-1,-1,-1,-1,-1,1,1,1,1,1,1,1])\n",
    "def pishbini(w0,w1,w2,xdata,ydata):\n",
    "    init_w=[float(w0),float(w1),float(w2)]\n",
    "    yhads=[]\n",
    "    for i in range(len(xdata)):\n",
    "        wXx0=xdata[i][0]*init_w[0]\n",
    "        wXx1=xdata[i][1]*init_w[1]\n",
    "        wXx2=xdata[i][2]*init_w[2]\n",
    "        SUM=wXx0+wXx1+wXx2\n",
    "        if SUM>=0:\n",
    "            SUM=1\n",
    "            yhads.append(SUM)\n",
    "        elif SUM <0 :\n",
    "            SUM=-1\n",
    "            yhads.append(SUM)\n",
    "    return yhads\n",
    "def wazn(w0,w1,w2,xdata,yPishbiniShode,yAsli,LR):\n",
    "    x=0\n",
    "    while x <= len(yAsli)-1:\n",
    "        if yPishbiniShode[x]!=yAsli[x]:\n",
    "            #print('eshtebah dar index :',x,' | y hads zade shode:',yPishbiniShode[x],' | y asli:',yAsli[x])   # etelaa az index eshtebah\n",
    "            wJadid0=w0 + ((xdata[x][0])*(yPishbiniShode[x])*(LR))\n",
    "            wJadid1=w1 + ((xdata[x][1])*(yPishbiniShode[x])*(LR))\n",
    "            wJadid2=w2 + ((xdata[x][2])*(yPishbiniShode[x])*(LR))\n",
    "            break\n",
    "        x+=1\n",
    "    return wJadid0,wJadid1,wJadid2\n",
    "def tekrar(initw0,initw1,initw2,LR):\n",
    "    print('====marhale====',0)\n",
    "    print('vaznHa  :',initw0,initw1,initw2)\n",
    "    hads0=pishbini(initw0,initw1,initw2,xData,yData)\n",
    "    w0,w1,w2=wazn(initw0,initw1,initw2,xData,yData,hads0,LR)\n",
    "    try:\n",
    "        x=0\n",
    "        while True:\n",
    "            print('====marhale====',x+1)\n",
    "            print('vaznHa  :{:.2f} | {:.2f} | {:.2f}'.format(w0,w1,w2))\n",
    "\n",
    "            hads=pishbini(w0,w1,w2,xData,yData)\n",
    "            w0,w1,w2=wazn(w0,w1,w2,xData,yData,hads,LR)\n",
    "            print('')\n",
    "            x+=1\n",
    "    except:\n",
    "        print('end')\n",
    "        return w0,w1,w2\n",
    "\n",
    "def deghat(yAsli,yHads):\n",
    "    emtiyaz=0\n",
    "    for i in range(len(yAsli)):\n",
    "        if yAsli[i] == yHads[i]:\n",
    "            emtiyaz+=1\n",
    "    deghaT=emtiyaz/len(yAsli)\n",
    "    return deghaT\n",
    "\n",
    "waznNahayi0,waznNahayi1,waznNahayi2=tekrar(0,0,0,1)  # (waznAvaliye0,waznAvaliye1,waznAvaliye2, learningRate)\n",
    "\n",
    "yhadszadeshode=pishbini(.4,0,.3,xData,yData)\n",
    "mohasebe_deghat=deghat(yData,yhadszadeshode)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fca522a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vaznhaye balatarin emtiaz:  | | -33.0 | | 9.0 | | -9.100000000000001\n",
      "pocket scores: [0, 0.4375, 0.5625, 0.6875, 0.75]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "xData2=np.array([[1 , 3 , 0.2],\n",
    "       [1 , 1 , 0.3],\n",
    "       [1 , 4 , 0.5],\n",
    "       [1 , 2 , 0.7],\n",
    "       [1 , 0 , 1. ],\n",
    "       [1 , 1 , 1.2],\n",
    "       [1 , 1 , 1.7],\n",
    "       [1 , 5 , 1. ],\n",
    "       [1 , 3 , 1.5],\n",
    "       [1 , 6 , 0.2],\n",
    "       [1 , 7 , 0.3],\n",
    "       [1 , 6 , 0.7],\n",
    "       [1 , 3 , 1.1],\n",
    "       [1 , 2 , 1.5],\n",
    "       [1 , 4 , 1.7],\n",
    "       [1 , 2 , 1.9]])\n",
    "yData2=np.array([-1,-1,-1,-1,-1,-1,-1,-1,-1,1,1,1,1,1,1,1,])\n",
    "\n",
    "def pocket(initw0,initw1,initw2,teedadMarahel,xdata,ydata,LR):\n",
    "    hads0=pishbini(initw0,initw1,initw2,xdata,ydata)\n",
    "    w0,w1,w2=wazn(initw0,initw1,initw2,xdata,ydata,hads0,LR)\n",
    "    jib=[0]\n",
    "    dd=deghat(ydata,hads0)\n",
    "    jib.append(dd)\n",
    "    try:\n",
    "        j=0\n",
    "        while j<teedadMarahel:\n",
    "            hads=pishbini(w0,w1,w2,xdata,ydata)\n",
    "            w0,w1,w2=wazn(w0,w1,w2,xdata,ydata,hads,LR)\n",
    "            dd=deghat(ydata,hads)\n",
    "            max_jib=max(jib)\n",
    "            if dd>max_jib:\n",
    "                \n",
    "                jib.append(dd)\n",
    "            j+=1\n",
    "        print('vaznhaye balatarin emtiaz: ',w0,w1,w2,sep = ' | | ')\n",
    "        return jib\n",
    "    except:\n",
    "        dd=deghat(ydata,hads)\n",
    "        jib.append(dd)\n",
    "        return jib\n",
    "    \n",
    "pscores=pocket(0,0,0,200,xData2,yData2,1) # (waznAvaliye0,waznAvaliye1,waznAvaliye2,TeedadMarahel, x data , y data , learning rate)\n",
    "print('pocket scores:',pscores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8811d03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------POCKET REPORT-----------------\n",
      "\n",
      "pocket scores: [0, 0.4375, 0.5625, 0.6875, 0.75]\n",
      "max score: 0.750\n",
      "the weights of index 1997  where max score is happend :\n",
      "[-42.0, 11.0, -5.199999999999836]\n",
      "max score epoch: 1997\n",
      "predicted:\n",
      " [-1, -1, -1, -1, -1, -1, -1, 1, -1, 1, 1, 1, -1, -1, -1, -1] \n",
      "True valu\n",
      " [-1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# ---------------\n",
    "# POCKET\n",
    "# ---------------\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------\n",
    "x_data2 = [\n",
    "    [3, 0.2],\n",
    "    [1, 0.3],\n",
    "    [4, 0.5],\n",
    "    [2, 0.7],\n",
    "    [0, 1],\n",
    "    [1, 1.2],\n",
    "    [1, 1.7],\n",
    "    [5, 1],\n",
    "    [3, 1.5],\n",
    "    [6, 0.2],\n",
    "    [7, 0.3],\n",
    "    [6, 0.7],\n",
    "    [3, 1.1],\n",
    "    [2, 1.5],\n",
    "    [4, 1.7],\n",
    "    [2, 1.9],\n",
    "]\n",
    "y_data2 = [\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    -1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "]\n",
    "y_data2 = np.array(y_data2)\n",
    "\n",
    "x_data2 = np.array(x_data2)\n",
    "x0 = np.ones(16)\n",
    "x0 = x0.reshape(16, 1)\n",
    "x_with_bias2 = np.concatenate((x0, x_data2), axis=1)\n",
    "# ------------------------------------------------------\n",
    "#\n",
    "# OOP\n",
    "#\n",
    "\n",
    "\n",
    "class POCKET:\n",
    "    def __init__(self, learning_rate, iteration, xx, yy):\n",
    "        self.learn = learning_rate\n",
    "        self.itr = iteration\n",
    "        self.x_data = xx\n",
    "        self.y_data = yy\n",
    "\n",
    "    def predict(self, w0, w1, w2):\n",
    "        self.initial_weights = [w0, w1, w2]\n",
    "        self.predicted = []\n",
    "        for i in self.x_data:\n",
    "            wx0 = i[0] * w0\n",
    "            wx1 = i[1] * w1\n",
    "            wx2 = i[2] * w2\n",
    "            summ = wx0 + wx1 + wx2\n",
    "            # print(summ)\n",
    "            if summ >= 0:\n",
    "                summ = 1\n",
    "                self.predicted.append(summ)\n",
    "            elif summ < 0:\n",
    "                summ = -1\n",
    "                self.predicted.append(summ)\n",
    "        return self.predicted\n",
    "\n",
    "    def update_weight(self):\n",
    "        w0, w1, w2 = self.initial_weights\n",
    "        ypred = np.array(self.predicted)\n",
    "        ypred = ypred.reshape(ypred.shape[0], 1)\n",
    "        yy0 = self.y_data.reshape(self.y_data.shape[0], 1)\n",
    "        y = np.concatenate((yy0, ypred), axis=1)\n",
    "        for i in range(len(y)):\n",
    "            A = y[i][0] != y[i][1]\n",
    "            if A == True:\n",
    "                self.mis_index = i\n",
    "                # print(self.mis_index,self.x_data[self.mis_index][0])\n",
    "                w0_new = w0 + (\n",
    "                    self.x_data[self.mis_index][0] * yy0[self.mis_index][0] * self.learn\n",
    "                )\n",
    "                w1_new = w1 + (\n",
    "                    self.x_data[self.mis_index][1] * yy0[self.mis_index][0] * self.learn\n",
    "                )\n",
    "                w2_new = w2 + (\n",
    "                    self.x_data[self.mis_index][2] * yy0[self.mis_index][0] * self.learn\n",
    "                )\n",
    "                break\n",
    "        # print(self.sto,self.y_data,sep='\\n')\n",
    "        # print(w0_new,w1_new,w2_new)\n",
    "        return w0_new, w1_new, w2_new\n",
    "\n",
    "    def do2(self, w, ww, www):\n",
    "        predict = self.predict(w, ww, www)\n",
    "        wn1, wn2, wn3 = self.update_weight()\n",
    "        return wn1, wn2, wn3\n",
    "\n",
    "    def accuracy(self):\n",
    "        # acc\n",
    "        self.y_data = self.y_data.reshape(self.y_data.shape[0], 1)\n",
    "        ypred = np.array(self.predicted)\n",
    "        ypred = ypred.reshape(ypred.shape[0], 1)\n",
    "        yy = np.concatenate((self.y_data, ypred), axis=1)\n",
    "        score = 0\n",
    "        for i, j in yy:\n",
    "            if i == j:\n",
    "                score += 1\n",
    "        self.sc = score / len(yy)\n",
    "        return self.sc\n",
    "\n",
    "    def pocket(self, weight0, weight1, weight2):\n",
    "        # pocket\n",
    "        epoch = 0\n",
    "        self.state = []\n",
    "        pocket_score = [0]\n",
    "        while epoch < self.itr:\n",
    "            try:\n",
    "                weight0, weight1, weight2 = self.do2(weight0, weight1, weight2)\n",
    "                score = self.accuracy()\n",
    "                if len(self.state) > 0:\n",
    "                    previous_score = self.state[-1][0]\n",
    "                    if previous_score > max(pocket_score):\n",
    "                        pocket_score.append(previous_score)\n",
    "\n",
    "                self.state.append([score, epoch, [weight0, weight1, weight2]])\n",
    "                epoch += 1\n",
    "            except:\n",
    "\n",
    "                break\n",
    "\n",
    "        self.state = np.array(self.state, dtype=\"object\")\n",
    "        return self.state, pocket_score\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "instancee = POCKET(1, 2000, x_with_bias2, y_data2)  # (learning_rate,iteration,x,y)\n",
    "stat, pocket = instancee.pocket(\n",
    "    0, 0, 0\n",
    ")  # (initialweight0,initialweight1,initialweight2)\n",
    "\n",
    "s, _ = np.where(stat == max(stat[:, 0]))\n",
    "index_num = s[-1]\n",
    "\n",
    "print(\n",
    "    \"-----------------POCKET REPORT-----------------\\n\\npocket scores: {}\".format(\n",
    "        pocket\n",
    "    ),\n",
    "    \"max score: {:.3f}\".format(max(stat[:, 0])),\n",
    "    \"the weights of index {}  where max score is happend :\".format(index_num),\n",
    "    \"{}\".format(stat[index_num, 2]),\n",
    "    \"max score epoch: {}\".format(index_num),\n",
    "    sep=\"\\n\",\n",
    ")\n",
    "print(\n",
    "    \"predicted:\\n\",\n",
    "    list(instancee.predict(-42, 11, -5.19)),\n",
    "    \"\\nTrue valu:\\n\",\n",
    "    list(y_data2),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f70ad3-f423-4ac0-af55-7145996b819b",
   "metadata": {},
   "source": [
    "----\n",
    "# perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a426ee2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights:0  0   0\n",
      " predicted: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] \n",
      "True value [-1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "epoch:0\n",
      "   weights 0.00   0.00   0.00\n",
      "score=0.50\n",
      "\n",
      "epoch:1\n",
      "   weights -1.00   -3.00   -0.20\n",
      "score=0.50\n",
      "\n",
      "epoch:2\n",
      "   weights 0.00   3.00   0.00\n",
      "score=0.50\n",
      "\n",
      "epoch:3\n",
      "   weights -1.00   0.00   -0.20\n",
      "score=0.50\n",
      "\n",
      "epoch:4\n",
      "   weights 0.00   6.00   0.00\n",
      "score=0.50\n",
      "\n",
      "epoch:5\n",
      "   weights -1.00   3.00   -0.20\n",
      "score=0.57\n",
      "\n",
      "epoch:6\n",
      "   weights -2.00   0.00   -0.40\n",
      "score=0.50\n",
      "\n",
      "epoch:7\n",
      "   weights -1.00   6.00   -0.20\n",
      "score=0.57\n",
      "\n",
      "epoch:8\n",
      "   weights -2.00   3.00   -0.40\n",
      "score=0.57\n",
      "\n",
      "epoch:9\n",
      "   weights -3.00   0.00   -0.60\n",
      "score=0.50\n",
      "\n",
      "epoch:10\n",
      "   weights -2.00   6.00   -0.40\n",
      "score=0.57\n",
      "\n",
      "epoch:11\n",
      "   weights -3.00   3.00   -0.60\n",
      "score=0.79\n",
      "\n",
      "epoch:12\n",
      "   weights -4.00   0.00   -0.80\n",
      "score=0.50\n",
      "\n",
      "epoch:13\n",
      "   weights -3.00   6.00   -0.60\n",
      "score=0.57\n",
      "\n",
      "epoch:14\n",
      "   weights -4.00   3.00   -0.80\n",
      "score=0.79\n",
      "\n",
      "epoch:15\n",
      "   weights -5.00   0.00   -1.00\n",
      "score=0.50\n",
      "\n",
      "epoch:16\n",
      "   weights -4.00   6.00   -0.80\n",
      "score=0.57\n",
      "\n",
      "epoch:17\n",
      "   weights -5.00   3.00   -1.00\n",
      "score=0.64\n",
      "\n",
      "epoch:18\n",
      "   weights -6.00   0.00   -1.20\n",
      "score=0.50\n",
      "\n",
      "epoch:19\n",
      "   weights -5.00   6.00   -1.00\n",
      "score=0.71\n",
      "\n",
      "epoch:20\n",
      "   weights -6.00   3.00   -1.20\n",
      "score=0.71\n",
      "\n",
      "epoch:21\n",
      "   weights -7.00   0.00   -1.40\n",
      "score=0.50\n",
      "\n",
      "epoch:22\n",
      "   weights -6.00   6.00   -1.20\n",
      "score=0.79\n",
      "\n",
      "epoch:23\n",
      "   weights -7.00   3.00   -1.40\n",
      "score=0.71\n",
      "\n",
      "epoch:24\n",
      "   weights -8.00   0.00   -1.60\n",
      "score=0.50\n",
      "\n",
      "epoch:25\n",
      "   weights -7.00   6.00   -1.40\n",
      "score=0.79\n",
      "\n",
      "epoch:26\n",
      "   weights -8.00   3.00   -1.60\n",
      "score=0.64\n",
      "\n",
      "epoch:27\n",
      "   weights -9.00   0.00   -1.80\n",
      "score=0.50\n",
      "\n",
      "epoch:28\n",
      "   weights -8.00   6.00   -1.60\n",
      "score=0.79\n",
      "\n",
      "epoch:29\n",
      "   weights -9.00   3.00   -1.80\n",
      "score=0.64\n",
      "\n",
      "epoch:30\n",
      "   weights -10.00   -1.00   -2.30\n",
      "score=0.50\n",
      "\n",
      "epoch:31\n",
      "   weights -9.00   5.00   -2.10\n",
      "score=0.71\n",
      "\n",
      "epoch:32\n",
      "   weights -10.00   2.00   -2.30\n",
      "score=0.71\n",
      "\n",
      "epoch:33\n",
      "   weights -9.00   5.00   -1.20\n",
      "score=0.64\n",
      "\n",
      "epoch:34\n",
      "   weights -10.00   2.00   -1.40\n",
      "score=0.71\n",
      "\n",
      "epoch:35\n",
      "   weights -9.00   5.00   -0.30\n",
      "score=0.79\n",
      "\n",
      "epoch:36\n",
      "   weights -10.00   2.00   -0.50\n",
      "score=0.71\n",
      "\n",
      "epoch:37\n",
      "   weights -9.00   5.00   0.60\n",
      "score=0.79\n",
      "\n",
      "epoch:38\n",
      "   weights -10.00   2.00   0.40\n",
      "score=0.71\n",
      "\n",
      "epoch:39\n",
      "   weights -9.00   5.00   1.50\n",
      "score=0.79\n",
      "\n",
      "epoch:40\n",
      "   weights -10.00   2.00   1.30\n",
      "score=0.79\n",
      "\n",
      "epoch:41\n",
      "   weights -9.00   5.00   2.40\n",
      "score=0.71\n",
      "\n",
      "epoch:42\n",
      "   weights -10.00   2.00   2.20\n",
      "score=0.79\n",
      "\n",
      "epoch:43\n",
      "   weights -9.00   5.00   3.30\n",
      "score=0.71\n",
      "\n",
      "epoch:44\n",
      "   weights -10.00   2.00   3.10\n",
      "score=0.79\n",
      "\n",
      "epoch:45\n",
      "   weights -9.00   5.00   4.20\n",
      "score=0.64\n",
      "\n",
      "epoch:46\n",
      "   weights -10.00   2.00   4.00\n",
      "score=0.93\n",
      "\n",
      "epoch:47\n",
      "   weights -11.00   -2.00   3.50\n",
      "score=0.50\n",
      "\n",
      "epoch:48\n",
      "   weights -10.00   4.00   3.70\n",
      "score=0.71\n",
      "\n",
      "epoch:49\n",
      "   weights -11.00   1.00   3.50\n",
      "score=0.50\n",
      "\n",
      "epoch:50\n",
      "   weights -10.00   7.00   3.70\n",
      "score=0.64\n",
      "\n",
      "epoch:51\n",
      "   weights -11.00   4.00   3.50\n",
      "score=0.86\n",
      "\n",
      "epoch:52\n",
      "   weights -12.00   1.00   3.30\n",
      "score=0.50\n",
      "\n",
      "epoch:53\n",
      "   weights -11.00   7.00   3.50\n",
      "score=0.64\n",
      "\n",
      "epoch:54\n",
      "   weights -12.00   4.00   3.30\n",
      "score=0.86\n",
      "\n",
      "epoch:55\n",
      "   weights -13.00   1.00   3.10\n",
      "score=0.50\n",
      "\n",
      "epoch:56\n",
      "   weights -12.00   7.00   3.30\n",
      "score=0.71\n",
      "\n",
      "epoch:57\n",
      "   weights -13.00   4.00   3.10\n",
      "score=0.86\n",
      "\n",
      "epoch:58\n",
      "   weights -14.00   0.00   2.60\n",
      "score=0.50\n",
      "\n",
      "epoch:59\n",
      "   weights -13.00   6.00   2.80\n",
      "score=0.79\n",
      "\n",
      "epoch:60\n",
      "   weights -14.00   3.00   2.60\n",
      "score=0.79\n",
      "\n",
      "epoch:61\n",
      "   weights -13.00   6.00   3.70\n",
      "score=0.79\n",
      "\n",
      "epoch:62\n",
      "   weights -14.00   3.00   3.50\n",
      "score=0.79\n",
      "\n",
      "epoch:63\n",
      "   weights -13.00   6.00   4.60\n",
      "score=0.71\n",
      "\n",
      "epoch:64\n",
      "   weights -14.00   3.00   4.40\n",
      "score=0.79\n",
      "\n",
      "epoch:65\n",
      "   weights -15.00   -1.00   3.90\n",
      "score=0.50\n",
      "\n",
      "epoch:66\n",
      "   weights -14.00   5.00   4.10\n",
      "score=0.86\n",
      "\n",
      "epoch:67\n",
      "   weights -15.00   2.00   3.90\n",
      "score=0.57\n",
      "\n",
      "epoch:68\n",
      "   weights -14.00   8.00   4.10\n",
      "score=0.71\n",
      "\n",
      "epoch:69\n",
      "   weights -15.00   5.00   3.90\n",
      "score=0.86\n",
      "\n",
      "epoch:70\n",
      "   weights -16.00   2.00   3.70\n",
      "score=0.50\n",
      "\n",
      "epoch:71\n",
      "   weights -15.00   8.00   3.90\n",
      "score=0.79\n",
      "\n",
      "epoch:72\n",
      "   weights -16.00   5.00   3.70\n",
      "score=0.86\n",
      "\n",
      "epoch:73\n",
      "   weights -17.00   1.00   3.20\n",
      "score=0.50\n",
      "\n",
      "epoch:74\n",
      "   weights -16.00   7.00   3.40\n",
      "score=0.79\n",
      "\n",
      "epoch:75\n",
      "   weights -17.00   4.00   3.20\n",
      "score=0.71\n",
      "\n",
      "epoch:76\n",
      "   weights -18.00   0.00   2.70\n",
      "score=0.50\n",
      "\n",
      "epoch:77\n",
      "   weights -17.00   6.00   2.90\n",
      "score=0.79\n",
      "\n",
      "epoch:78\n",
      "   weights -18.00   3.00   2.70\n",
      "score=0.71\n",
      "\n",
      "epoch:79\n",
      "   weights -17.00   6.00   3.80\n",
      "score=0.86\n",
      "\n",
      "epoch:80\n",
      "   weights -18.00   3.00   3.60\n",
      "score=0.79\n",
      "\n",
      "epoch:81\n",
      "   weights -17.00   6.00   4.70\n",
      "score=0.86\n",
      "\n",
      "epoch:82\n",
      "   weights -18.00   3.00   4.50\n",
      "score=0.79\n",
      "\n",
      "epoch:83\n",
      "   weights -17.00   6.00   5.60\n",
      "score=0.86\n",
      "\n",
      "epoch:84\n",
      "   weights -18.00   3.00   5.40\n",
      "score=0.79\n",
      "\n",
      "epoch:85\n",
      "   weights -17.00   6.00   6.50\n",
      "score=0.79\n",
      "\n",
      "epoch:86\n",
      "   weights -18.00   3.00   6.30\n",
      "score=0.79\n",
      "\n",
      "epoch:87\n",
      "   weights -17.00   6.00   7.40\n",
      "score=0.71\n",
      "\n",
      "epoch:88\n",
      "   weights -18.00   3.00   7.20\n",
      "score=0.86\n",
      "\n",
      "epoch:89\n",
      "   weights -17.00   6.00   8.30\n",
      "score=0.71\n",
      "\n",
      "epoch:90\n",
      "   weights -18.00   3.00   8.10\n",
      "score=0.93\n",
      "\n",
      "epoch:91\n",
      "   weights -17.00   6.00   9.20\n",
      "score=0.64\n",
      "\n",
      "epoch:92\n",
      "   weights -18.00   3.00   9.00\n",
      "score=0.93\n",
      "\n",
      "epoch:93\n",
      "   weights -19.00   2.00   7.30\n",
      "score=0.57\n",
      "\n",
      "epoch:94\n",
      "   weights -18.00   8.00   7.50\n",
      "score=0.71\n",
      "\n",
      "epoch:95\n",
      "   weights -19.00   5.00   7.30\n",
      "score=0.93\n",
      "\n",
      "epoch:96\n",
      "   weights -20.00   1.00   6.80\n",
      "score=0.50\n",
      "\n",
      "epoch:97\n",
      "   weights -19.00   7.00   7.00\n",
      "score=0.86\n",
      "\n",
      "epoch:98\n",
      "   weights -20.00   4.00   6.80\n",
      "score=0.86\n",
      "\n",
      "epoch:99\n",
      "   weights -19.00   7.00   7.90\n",
      "score=0.71\n",
      "\n",
      "epoch:100\n",
      "   weights -20.00   4.00   7.70\n",
      "score=0.93\n",
      "\n",
      "epoch:101\n",
      "   weights -19.00   6.00   9.20\n",
      "score=0.79\n",
      "\n",
      "epoch:102\n",
      "   weights -20.00   3.00   9.00\n",
      "score=0.79\n",
      "\n",
      "epoch:103\n",
      "   weights -19.00   9.00   9.20\n",
      "score=0.64\n",
      "\n",
      "epoch:104\n",
      "   weights -20.00   6.00   9.00\n",
      "score=0.86\n",
      "\n",
      "epoch:105\n",
      "   weights -21.00   2.00   8.50\n",
      "score=0.57\n",
      "\n",
      "epoch:106\n",
      "   weights -20.00   8.00   8.70\n",
      "score=0.71\n",
      "\n",
      "epoch:107\n",
      "   weights -21.00   5.00   8.50\n",
      "score=0.93\n",
      "\n",
      "epoch:108\n",
      "   weights -22.00   1.00   8.00\n",
      "score=0.50\n",
      "\n",
      "epoch:109\n",
      "   weights -21.00   7.00   8.20\n",
      "score=0.86\n",
      "\n",
      "epoch:110\n",
      "   weights -22.00   4.00   8.00\n",
      "score=0.86\n",
      "\n",
      "epoch:111\n",
      "   weights -21.00   7.00   9.10\n",
      "score=0.79\n",
      "\n",
      "epoch:112\n",
      "   weights -22.00   4.00   8.90\n",
      "score=0.86\n",
      "\n",
      "epoch:113\n",
      "   weights -21.00   7.00   10.00\n",
      "score=0.71\n",
      "\n",
      "epoch:114\n",
      "   weights -22.00   4.00   9.80\n",
      "score: 1.00\n",
      "----\n",
      "end of optimization----\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "# ------------------------------------------------------\n",
    "xData = np.array([[1 , 3 , 0.2],\n",
    "       [1 , 1 , 0.3],\n",
    "       [1 , 4 , 0.5],\n",
    "       [1 , 2 , 0.7],\n",
    "       [1 , 0 , 1. ],\n",
    "       [1 , 1 , 1.2],\n",
    "       [1 , 1 , 1.7],\n",
    "       [1 , 6 , 0.2],\n",
    "       [1 , 7 , 0.3],\n",
    "       [1 , 6 , 0.7],\n",
    "       [1 , 3 , 1.1],\n",
    "       [1 , 2 , 1.5],\n",
    "       [1 , 4 , 1.7],\n",
    "       [1 , 2 , 1.9]])\n",
    "yData = np.array([-1,-1,-1,-1,-1,-1,-1,1,1,1,1,1,1,1])\n",
    "x_data1 = [\n",
    "    [3, 0.2],\n",
    "    [1, 0.3],\n",
    "    [4, 0.5],\n",
    "    [2, 0.7],\n",
    "    [0, 1],\n",
    "    [1, 1.2],\n",
    "    [1, 1.7],\n",
    "    [6, 0.2],\n",
    "    [7, 0.3],\n",
    "    [6, 0.7],\n",
    "    [3, 1.1],\n",
    "    [2, 1.5],\n",
    "    [4, 1.7],\n",
    "    [2, 1.9],\n",
    "]\n",
    "y_data1 = [-1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1]\n",
    "y_data1 = np.array(y_data1)\n",
    "\n",
    "x_data1 = np.array(x_data1)\n",
    "x01 = np.ones(14)\n",
    "x01 = x01.reshape(14, 1)\n",
    "x_with_bias1 = np.concatenate((x01, x_data1), axis=1)\n",
    "# ------------------------------------------------------\n",
    "# OOP\n",
    "\n",
    "class PERCEPTRON:\n",
    "    \"\"\"\n",
    "    for classify linearly separable data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate, xx, yy):\n",
    "        self.learn = learning_rate\n",
    "        self.x_data = xx\n",
    "        self.y_data = yy\n",
    "        self.state = []\n",
    "\n",
    "    def predict(self, w0, w1, w2):\n",
    "        self.initial_weights = [w0, w1, w2]\n",
    "        self.predicted = []\n",
    "        for i in self.x_data:\n",
    "            wx0 = i[0] * w0\n",
    "            wx1 = i[1] * w1\n",
    "            wx2 = i[2] * w2\n",
    "            summ = wx0 + wx1 + wx2\n",
    "            # print(summ)\n",
    "            if summ >= 0:\n",
    "                summ = 1\n",
    "                self.predicted.append(summ)\n",
    "            elif summ < 0:\n",
    "                summ = -1\n",
    "                self.predicted.append(summ)\n",
    "        return self.predicted\n",
    "\n",
    "    def update_weight(self):\n",
    "        w0, w1, w2 = self.initial_weights\n",
    "        ypred = np.array(self.predicted)\n",
    "        ypred = ypred.reshape(ypred.shape[0], 1)\n",
    "        yy0 = self.y_data.reshape(self.y_data.shape[0], 1)\n",
    "        y = np.concatenate((yy0, ypred), axis=1)\n",
    "        for i in range(len(y)):\n",
    "            A = y[i][0] != y[i][1]\n",
    "            if A == True:\n",
    "                self.mis_index = i\n",
    "                # print(self.mis_index,self.x_data[self.mis_index][0])\n",
    "                w0_new = w0 + (\n",
    "                    self.x_data[self.mis_index][0] * yy0[self.mis_index][0] * self.learn\n",
    "                )\n",
    "                w1_new = w1 + (\n",
    "                    self.x_data[self.mis_index][1] * yy0[self.mis_index][0] * self.learn\n",
    "                )\n",
    "                w2_new = w2 + (\n",
    "                    self.x_data[self.mis_index][2] * yy0[self.mis_index][0] * self.learn\n",
    "                )\n",
    "                break\n",
    "        # print(self.sto,self.y_data,sep='\\n')\n",
    "        # print(w0_new,w1_new,w2_new)\n",
    "        return w0_new, w1_new, w2_new\n",
    "\n",
    "    def do2(self, w, ww, www):\n",
    "        predict = self.predict(w, ww, www)\n",
    "        wn1, wn2, wn3 = self.update_weight()\n",
    "        return wn1, wn2, wn3\n",
    "\n",
    "    def fit(self, weight0, weight1, weight2):\n",
    "        epoch = 0\n",
    "        while True:\n",
    "            try:\n",
    "                print(\"\\nepoch:{}\".format(epoch))\n",
    "                print(\n",
    "                    \"   weights {:.2f}   {:.2f}   {:.2f}\".format(\n",
    "                        weight0, weight1, weight2\n",
    "                    )\n",
    "                )\n",
    "                weight0, weight1, weight2 = self.do2(weight0, weight1, weight2)\n",
    "                score = self.accuracy()\n",
    "                print(\"score={:.2f}\".format(score))\n",
    "                self.state.append([score, epoch, [weight0, weight1, weight2]])\n",
    "                epoch += 1\n",
    "            except:\n",
    "                score = self.accuracy()\n",
    "                print(\"score: {:.2f}\".format(self.accuracy()))\n",
    "                self.state.append([score, epoch, [weight0, weight1, weight2]])\n",
    "                print(\"----\\nend of optimization----\")\n",
    "                break\n",
    "        self.state = np.array(self.state, dtype=\"object\")\n",
    "        return self.state\n",
    "\n",
    "    def accuracy(self):\n",
    "        # acc\n",
    "        self.y_data = self.y_data.reshape(self.y_data.shape[0], 1)\n",
    "        ypred = np.array(self.predicted)\n",
    "        ypred = ypred.reshape(ypred.shape[0], 1)\n",
    "        yy = np.concatenate((self.y_data, ypred), axis=1)\n",
    "        score = 0\n",
    "        for i, j in yy:\n",
    "            if i == j:\n",
    "                score += 1\n",
    "        self.sc = score / len(yy)\n",
    "        return self.sc\n",
    "\n",
    "\n",
    "# ----------------------------------------------\n",
    "instancee = PERCEPTRON(1, x_with_bias1, y_data1)\n",
    "# weight needed to predicted\n",
    "w0, w1, w2 = 0, 0, 0\n",
    "\n",
    "print(\n",
    "    \"weights:{}  {}   {}\\n\".format(w0, w1, w2),\n",
    "    \"predicted:\",instancee.predict(w0, w1, w2),\n",
    "    \"\\nTrue value\",\n",
    "    list(y_data1),\n",
    ")\n",
    "\n",
    "state = instancee.fit(0, 0, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b67d88d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fee6bc6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch:0\n",
      "   weights 1.00   1.00   1.00\n",
      "score=0.50\n",
      "\n",
      "epoch:1\n",
      "   weights 0.00   -2.00   0.80\n",
      "score=0.43\n",
      "\n",
      "epoch:2\n",
      "   weights -1.00   -2.00   -0.20\n",
      "score=0.50\n",
      "\n",
      "epoch:3\n",
      "   weights 0.00   4.00   0.00\n",
      "score=0.50\n",
      "\n",
      "epoch:4\n",
      "   weights -1.00   1.00   -0.20\n",
      "score=0.79\n",
      "\n",
      "epoch:5\n",
      "   weights -2.00   -2.00   -0.40\n",
      "score=0.50\n",
      "\n",
      "epoch:6\n",
      "   weights -1.00   4.00   -0.20\n",
      "score=0.57\n",
      "\n",
      "epoch:7\n",
      "   weights -2.00   1.00   -0.40\n",
      "score=0.71\n",
      "\n",
      "epoch:8\n",
      "   weights -3.00   -2.00   -0.60\n",
      "score=0.50\n",
      "\n",
      "epoch:9\n",
      "   weights -2.00   4.00   -0.40\n",
      "score=0.57\n",
      "\n",
      "epoch:10\n",
      "   weights -3.00   1.00   -0.60\n",
      "score=0.64\n",
      "\n",
      "epoch:11\n",
      "   weights -4.00   -3.00   -1.10\n",
      "score=0.50\n",
      "\n",
      "epoch:12\n",
      "   weights -3.00   3.00   -0.90\n",
      "score=0.79\n",
      "\n",
      "epoch:13\n",
      "   weights -4.00   0.00   -1.10\n",
      "score=0.50\n",
      "\n",
      "epoch:14\n",
      "   weights -3.00   6.00   -0.90\n",
      "score=0.57\n",
      "\n",
      "epoch:15\n",
      "   weights -4.00   3.00   -1.10\n",
      "score=0.71\n",
      "\n",
      "epoch:16\n",
      "   weights -5.00   0.00   -1.30\n",
      "score=0.50\n",
      "\n",
      "epoch:17\n",
      "   weights -4.00   6.00   -1.10\n",
      "score=0.57\n",
      "\n",
      "epoch:18\n",
      "   weights -5.00   3.00   -1.30\n",
      "score=0.64\n",
      "\n",
      "epoch:19\n",
      "   weights -6.00   0.00   -1.50\n",
      "score=0.50\n",
      "\n",
      "epoch:20\n",
      "   weights -5.00   6.00   -1.30\n",
      "score=0.71\n",
      "\n",
      "epoch:21\n",
      "   weights -6.00   3.00   -1.50\n",
      "score=0.71\n",
      "\n",
      "epoch:22\n",
      "   weights -7.00   0.00   -1.70\n",
      "score=0.50\n",
      "\n",
      "epoch:23\n",
      "   weights -6.00   6.00   -1.50\n",
      "score=0.79\n",
      "\n",
      "epoch:24\n",
      "   weights -7.00   3.00   -1.70\n",
      "score=0.71\n",
      "\n",
      "epoch:25\n",
      "   weights -8.00   0.00   -1.90\n",
      "score=0.50\n",
      "\n",
      "epoch:26\n",
      "   weights -7.00   6.00   -1.70\n",
      "score=0.79\n",
      "\n",
      "epoch:27\n",
      "   weights -8.00   3.00   -1.90\n",
      "score=0.64\n",
      "\n",
      "epoch:28\n",
      "   weights -9.00   0.00   -2.10\n",
      "score=0.50\n",
      "\n",
      "epoch:29\n",
      "   weights -8.00   6.00   -1.90\n",
      "score=0.79\n",
      "\n",
      "epoch:30\n",
      "   weights -9.00   3.00   -2.10\n",
      "score=0.64\n",
      "\n",
      "epoch:31\n",
      "   weights -10.00   -1.00   -2.60\n",
      "score=0.50\n",
      "\n",
      "epoch:32\n",
      "   weights -9.00   5.00   -2.40\n",
      "score=0.71\n",
      "\n",
      "epoch:33\n",
      "   weights -10.00   2.00   -2.60\n",
      "score=0.71\n",
      "\n",
      "epoch:34\n",
      "   weights -9.00   5.00   -1.50\n",
      "score=0.71\n",
      "\n",
      "epoch:35\n",
      "   weights -10.00   2.00   -1.70\n",
      "score=0.71\n",
      "\n",
      "epoch:36\n",
      "   weights -9.00   5.00   -0.60\n",
      "score=0.71\n",
      "\n",
      "epoch:37\n",
      "   weights -10.00   2.00   -0.80\n",
      "score=0.71\n",
      "\n",
      "epoch:38\n",
      "   weights -9.00   5.00   0.30\n",
      "score=0.79\n",
      "\n",
      "epoch:39\n",
      "   weights -10.00   2.00   0.10\n",
      "score=0.71\n",
      "\n",
      "epoch:40\n",
      "   weights -9.00   5.00   1.20\n",
      "score=0.79\n",
      "\n",
      "epoch:41\n",
      "   weights -10.00   2.00   1.00\n",
      "score=0.71\n",
      "\n",
      "epoch:42\n",
      "   weights -9.00   5.00   2.10\n",
      "score=0.79\n",
      "\n",
      "epoch:43\n",
      "   weights -10.00   2.00   1.90\n",
      "score=0.79\n",
      "\n",
      "epoch:44\n",
      "   weights -9.00   5.00   3.00\n",
      "score=0.71\n",
      "\n",
      "epoch:45\n",
      "   weights -10.00   2.00   2.80\n",
      "score=0.79\n",
      "\n",
      "epoch:46\n",
      "   weights -9.00   5.00   3.90\n",
      "score=0.64\n",
      "\n",
      "epoch:47\n",
      "   weights -10.00   2.00   3.70\n",
      "score=0.93\n",
      "\n",
      "epoch:48\n",
      "   weights -9.00   4.00   5.20\n",
      "score=0.64\n",
      "\n",
      "epoch:49\n",
      "   weights -10.00   1.00   5.00\n",
      "score=0.64\n",
      "\n",
      "epoch:50\n",
      "   weights -9.00   7.00   5.20\n",
      "score=0.64\n",
      "\n",
      "epoch:51\n",
      "   weights -10.00   4.00   5.00\n",
      "score=0.64\n",
      "\n",
      "epoch:52\n",
      "   weights -11.00   1.00   4.80\n",
      "score=0.64\n",
      "\n",
      "epoch:53\n",
      "   weights -10.00   7.00   5.00\n",
      "score=0.64\n",
      "\n",
      "epoch:54\n",
      "   weights -11.00   4.00   4.80\n",
      "score=0.71\n",
      "\n",
      "epoch:55\n",
      "   weights -12.00   1.00   4.60\n",
      "score=0.50\n",
      "\n",
      "epoch:56\n",
      "   weights -11.00   7.00   4.80\n",
      "score=0.64\n",
      "\n",
      "epoch:57\n",
      "   weights -12.00   4.00   4.60\n",
      "score=0.86\n",
      "\n",
      "epoch:58\n",
      "   weights -13.00   1.00   4.40\n",
      "score=0.50\n",
      "\n",
      "epoch:59\n",
      "   weights -12.00   7.00   4.60\n",
      "score=0.64\n",
      "\n",
      "epoch:60\n",
      "   weights -13.00   4.00   4.40\n",
      "score=0.93\n",
      "\n",
      "epoch:61\n",
      "   weights -14.00   0.00   3.90\n",
      "score=0.50\n",
      "\n",
      "epoch:62\n",
      "   weights -13.00   6.00   4.10\n",
      "score=0.79\n",
      "\n",
      "epoch:63\n",
      "   weights -14.00   3.00   3.90\n",
      "score=0.79\n",
      "\n",
      "epoch:64\n",
      "   weights -13.00   6.00   5.00\n",
      "score=0.71\n",
      "\n",
      "epoch:65\n",
      "   weights -14.00   3.00   4.80\n",
      "score=0.86\n",
      "\n",
      "epoch:66\n",
      "   weights -15.00   -1.00   4.30\n",
      "score=0.50\n",
      "\n",
      "epoch:67\n",
      "   weights -14.00   5.00   4.50\n",
      "score=0.86\n",
      "\n",
      "epoch:68\n",
      "   weights -15.00   2.00   4.30\n",
      "score=0.71\n",
      "\n",
      "epoch:69\n",
      "   weights -14.00   8.00   4.50\n",
      "score=0.71\n",
      "\n",
      "epoch:70\n",
      "   weights -15.00   5.00   4.30\n",
      "score=0.86\n",
      "\n",
      "epoch:71\n",
      "   weights -16.00   2.00   4.10\n",
      "score=0.50\n",
      "\n",
      "epoch:72\n",
      "   weights -15.00   8.00   4.30\n",
      "score=0.71\n",
      "\n",
      "epoch:73\n",
      "   weights -16.00   5.00   4.10\n",
      "score=0.93\n",
      "\n",
      "epoch:74\n",
      "   weights -17.00   1.00   3.60\n",
      "score=0.50\n",
      "\n",
      "epoch:75\n",
      "   weights -16.00   7.00   3.80\n",
      "score=0.79\n",
      "\n",
      "epoch:76\n",
      "   weights -17.00   4.00   3.60\n",
      "score=0.71\n",
      "\n",
      "epoch:77\n",
      "   weights -18.00   0.00   3.10\n",
      "score=0.50\n",
      "\n",
      "epoch:78\n",
      "   weights -17.00   6.00   3.30\n",
      "score=0.79\n",
      "\n",
      "epoch:79\n",
      "   weights -18.00   3.00   3.10\n",
      "score=0.71\n",
      "\n",
      "epoch:80\n",
      "   weights -17.00   6.00   4.20\n",
      "score=0.86\n",
      "\n",
      "epoch:81\n",
      "   weights -18.00   3.00   4.00\n",
      "score=0.79\n",
      "\n",
      "epoch:82\n",
      "   weights -17.00   6.00   5.10\n",
      "score=0.86\n",
      "\n",
      "epoch:83\n",
      "   weights -18.00   3.00   4.90\n",
      "score=0.79\n",
      "\n",
      "epoch:84\n",
      "   weights -17.00   6.00   6.00\n",
      "score=0.86\n",
      "\n",
      "epoch:85\n",
      "   weights -18.00   3.00   5.80\n",
      "score=0.79\n",
      "\n",
      "epoch:86\n",
      "   weights -17.00   6.00   6.90\n",
      "score=0.79\n",
      "\n",
      "epoch:87\n",
      "   weights -18.00   3.00   6.70\n",
      "score=0.86\n",
      "\n",
      "epoch:88\n",
      "   weights -17.00   6.00   7.80\n",
      "score=0.71\n",
      "\n",
      "epoch:89\n",
      "   weights -18.00   3.00   7.60\n",
      "score=0.86\n",
      "\n",
      "epoch:90\n",
      "   weights -17.00   6.00   8.70\n",
      "score=0.71\n",
      "\n",
      "epoch:91\n",
      "   weights -18.00   3.00   8.50\n",
      "score: 1.00\n",
      "----\n",
      "end of optimization----\n"
     ]
    }
   ],
   "source": [
    "instancee=PERCEPTRON(1,x_with_bias1,y_data1)\n",
    "state=instancee.fit(1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee326e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, -1, -1, -1, -1, -1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instancee.predict(-18.8,3.09,8.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ce681de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4308/2684500426.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'perceptron progress'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoches'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stat' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(stat[:,1],stat[:,0])\n",
    "plt.title('perceptron progress')\n",
    "plt.xlabel('epoches')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8462dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e35127d",
   "metadata": {},
   "source": [
    "# --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dea64be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
